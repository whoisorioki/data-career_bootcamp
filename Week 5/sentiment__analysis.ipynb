{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "RsxtYj1sKXXe",
        "outputId": "6eff54b6-b8d8-42f1-b087-e126ca7b1227"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import pyforest\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CsAM_dgZLddz"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>ID</th>\n",
              "      <th>datetime</th>\n",
              "      <th>query</th>\n",
              "      <th>username</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment          ID                      datetime     query  \\\n",
              "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
              "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
              "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
              "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "\n",
              "          username                                               text  \n",
              "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
              "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
              "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
              "4           Karoli  @nationwideclass no, it's not behaving at all....  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read the CSV file\n",
        "columns  = [\"sentiment\", \"ID\", \"datetime\", \"query\", \"username\", \"text\"]\n",
        "df = pd.read_csv('sentiment_dataset.csv', delimiter=',', encoding = \"ISO-8859-1\", names = columns)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6_poAUzuRcVw"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                               text\n",
              "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  is upset that he can't update his Facebook by ...\n",
              "2          0  @Kenichan I dived many times for the ball. Man...\n",
              "3          0    my whole body feels itchy and like its on fire \n",
              "4          0  @nationwideclass no, it's not behaving at all...."
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Extract sentiment and text column, they will be relevant in this analysis\n",
        "df = df[['sentiment','text']]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_ifPK0G-Uzhm"
      },
      "outputs": [],
      "source": [
        "# # Fuction that performs cleaning using re library. \n",
        "# # It removes uppercase, brackets, links, punctuation etc\n",
        "# def cleaning(a):\n",
        "#     a = str(a).lower()\n",
        "#     a = re.sub('\\[.*?\\]', '', a)\n",
        "#     a = re.sub('[%s]' % re.escape(string.punctuation), '', a)\n",
        "#     a = re.sub('\\n', '', a)\n",
        "#     a = re.sub('https?://\\S+|www\\.\\S+', '', a)\n",
        "#     a = re.sub('<.*?>+', '', a)\n",
        "#     a = re.sub('\\w*\\d\\w*', '', a)\n",
        "#     return a\n",
        "\n",
        "# df['text'] = df['text'].apply(cleaning)\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Removing the URl using re\n",
        "\n",
        "def rem_url(text):\n",
        "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url.sub(r'',text)\n",
        "\n",
        "# Removing the stepwords 'english'\n",
        "\n",
        "def rem_stopwords(text):\n",
        "    text = ' '.join([word for word in text.split() if word not in (stopwords.words('english'))])\n",
        "    return text\n",
        "\n",
        "# Removing the html \n",
        "\n",
        "def rem_html(text):\n",
        "    html=re.compile(r'<.*?>')\n",
        "    return html.sub(r'',text)\n",
        "\n",
        "#Removing the @\n",
        "\n",
        "def remove_at_mentions(text):\n",
        "    return re.sub(r'@\\w+', '', text)\n",
        "\n",
        "\n",
        "# Removing emojis by codes\n",
        "\n",
        "def rem_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  \n",
        "                           u\"\\U0001F300-\\U0001F5FF\" \n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "\n",
        "# Fixing the text\n",
        "\n",
        "def fixing(text):\n",
        "    text = re.sub(r\"Mr\\'s\", \" he is\", text)\n",
        "    text = re.sub(r\"Mr\\'.\", \" he is\", text)\n",
        "    text = re.sub(r\"Ms\\'.\", \" She \", text)\n",
        "    text = re.sub(r\"She\\'s\", \" she is\", text)\n",
        "    text = re.sub(r\"I\\'m\", \" i am\", text)\n",
        "    text = re.sub(r\"haven\\'t\", \" have not\", text)\n",
        "    text = re.sub(r\"you\\'r\", \" you are\", text)\n",
        "    text = re.sub(r\"won\\'t\", \" will not\", text)\n",
        "    text = re.sub(r\"won\\'t've\", \" will not have\", text)\n",
        "    text = re.sub(r\"can\\'t\", \" can not\", text)\n",
        "    text = re.sub(r\"don\\'t\", \" do not\", text)\n",
        "    text = re.sub(r\" plz\", \" please\", text)\n",
        "    text = re.sub(r\"it\\'s\", \" its\", text) \n",
        "    text = re.sub(r\"can\\'t've\", \" can not have\", text)\n",
        "    text = re.sub(r\"ma\\'am\", \" madam\", text)\n",
        "    text = re.sub(r\"let\\'s\", \" let us\", text)\n",
        "    text = re.sub(r\"ain\\'t\", \" am not\", text)\n",
        "    text = re.sub(r\"shan\\'t\", \" shall not\", text)\n",
        "    text = re.sub(r\"sha\\n't\", \" shall not\", text)\n",
        "    text = re.sub(r\"o\\'clock\", \" of the clock\", text)\n",
        "    text = re.sub(r\"y\\'all\", \" you all\", text)\n",
        "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"n\\'t've\", \" not have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'s\", \" is\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'d've\", \" would have\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ll've\", \" will have\", text)\n",
        "    text = re.sub(r\"\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'m\", \" am\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"He\\'s\", \" he is\", text)\n",
        "    text = re.sub(r\"in\\'s\", \" in\", text)\n",
        "    return text\n",
        "\n",
        "# Seperate alphabets\n",
        "\n",
        "def sep_alphabets(text):\n",
        "    words = text\n",
        "    words = re.findall(r\"[^\\W\\d_]+|\\d+\", words)\n",
        "    return \" \".join(words)\n",
        "\n",
        "\n",
        "def tweet_to_words(tweet):\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\", \" \",tweet) \n",
        "    words = letters_only.lower().split()                             \n",
        "    stops = set(stopwords.words(\"english\"))                  \n",
        "    meaningful_words = [w for w in words if not w in stops] \n",
        "    return( \" \".join( meaningful_words ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['final_text'] = df['text']\n",
        "\n",
        "df['final_text'] = df['final_text'].astype(str).apply(remove_at_mentions)\n",
        "df['final_text'] = df['final_text'].apply(lambda x : rem_url(x))\n",
        "df['final_text'] = df['final_text'].apply(lambda x : rem_stopwords(x))\n",
        "df['final_text'] = df['final_text'].apply(lambda x : rem_html(x))\n",
        "df['final_text'] = df['final_text'].apply(lambda x : rem_emoji(x))\n",
        "df['final_text'] = df['final_text'].apply(lambda x : fixing(x))\n",
        "df['final_text'] = df['final_text'].apply(lambda x : sep_alphabets(x))\n",
        "df['final_text'] = df['final_text'].apply(lambda x : tweet_to_words(x))\n",
        "df['final_text'] = df['final_text'].astype(str).replace(\"plz\", \"please\", regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxvEarRpVtvC"
      },
      "outputs": [],
      "source": [
        "# Checking for balance\n",
        "df['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z90pOfsAXko1"
      },
      "outputs": [],
      "source": [
        "# # Removing stop words i.e., the, is, and, or, in, this etc\n",
        "# s_words = stopwords.words('english')\n",
        "\n",
        "# def removing(text):\n",
        "#     a = ' '.join(i for i in text.split(' ') if i not in s_words)\n",
        "#     return a\n",
        "    \n",
        "# df['text'] = df['text'].apply(removing)\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gfTs0lDaTwH"
      },
      "outputs": [],
      "source": [
        "# Change 0 to negative and 4 to positive\n",
        "class_dict = {0:'negative', 4:'positive'}\n",
        "df['sentiment'] = df['sentiment'].apply(lambda x:  class_dict[x])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJdBJ-6obsjZ"
      },
      "outputs": [],
      "source": [
        "# # Stemming words that have same meaning\n",
        "# stemmer = nltk.SnowballStemmer(\"english\")\n",
        "\n",
        "# def stemming(text):\n",
        "#     text = ' '.join(stemmer.stem(i) for i in text.split(' '))\n",
        "#     return text\n",
        "\n",
        "# df['text'] = df['text'].apply(stemming)\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ra1-djeYe6i-"
      },
      "outputs": [],
      "source": [
        "# Split the data to train data and test data\n",
        "X = df['text']\n",
        "y = df['sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzymzsE2fSUp"
      },
      "outputs": [],
      "source": [
        "# Using Logistic Regression\n",
        "clf = LogisticRegression(penalty=\"l2\", random_state=42, C=0.01)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(\"Training Accuracy:\", clf.score(X_train, y_train))\n",
        "print(\"Testing Accuracy:\", clf.score(X_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMii7XuhR1ZB6eIMIM6pNSR",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
